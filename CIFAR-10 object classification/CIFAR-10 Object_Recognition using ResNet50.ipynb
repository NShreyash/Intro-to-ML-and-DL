{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setting up Kaggle for the DL Model and downloading the dataset"
      ],
      "metadata": {
        "id": "8DRq0jL_Jjr_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLpEj1jDPnTe"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuring the path of kaggle.json file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Llo6uQ5kPsVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading Dataset using API\n",
        "!kaggle competitions download -c cifar-10"
      ],
      "metadata": {
        "id": "59U7JdfpGqvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "metadata": {
        "id": "WnRtSEz4G43f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the compressed folder\n",
        "from zipfile import ZipFile\n",
        "dataset = \"/content/cifar-10.zip\"\n",
        "\n",
        "with ZipFile(dataset, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The dataset is successfully extracted')\n"
      ],
      "metadata": {
        "id": "t2lbQ1n0HJcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "id": "M2Lz9axKH8mZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing py7zr library to extract train.7z file\n",
        "! pip install py7zr"
      ],
      "metadata": {
        "id": "_o0rB_qcIEpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import py7zr\n",
        "archive = py7zr.SevenZipFile('/content/train.7z', mode='r')\n",
        "archive.extractall()\n",
        "archive.close()"
      ],
      "metadata": {
        "id": "vKaLIjDeIKT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "metadata": {
        "id": "wGuFWSPPIqt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Importing the Libraries"
      ],
      "metadata": {
        "id": "AY8tOtakJsWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "fo_bODNRK944"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Having a look at training data\n",
        "filenames = os.listdir(\"/content/train\")\n",
        "print(filenames)"
      ],
      "metadata": {
        "id": "Yh1IkOgAMoAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(filenames)"
      ],
      "metadata": {
        "id": "Y_X3v8iqPbBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(filenames)"
      ],
      "metadata": {
        "id": "LQ8m51uDPoVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(filenames[0:5])\n",
        "print(filenames[-5:])"
      ],
      "metadata": {
        "id": "Be1lCYTsP1Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Processing the Labels"
      ],
      "metadata": {
        "id": "sP_2aGTnQ6m-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df = pd.read_csv(\"/content/trainLabels.csv\")\n",
        "labels_df.head(10)"
      ],
      "metadata": {
        "id": "z3UEqxlUQfyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df.shape"
      ],
      "metadata": {
        "id": "8aCOZRXzRek3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df[labels_df['id'] == 2351] #example"
      ],
      "metadata": {
        "id": "F0CTmDSjRrAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df['label'].value_counts()"
      ],
      "metadata": {
        "id": "xCmPECqiSG2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding label strings to numerics using dictionaries' key value pairs\n",
        "labels_dictionary ={'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9 }\n",
        "\n",
        "labels = [labels_dictionary[i] for i in labels_df['label']]\n"
      ],
      "metadata": {
        "id": "qxIuIBBDhK_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(labels)"
      ],
      "metadata": {
        "id": "790L5nnTXxuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels[0:5]) #example"
      ],
      "metadata": {
        "id": "SJf8nQUfX_Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels)"
      ],
      "metadata": {
        "id": "2rwkrDptYCaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Processing the images training dataset"
      ],
      "metadata": {
        "id": "MLvoDTKcauGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying sample image\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow # This step is required because colab does not support cv2.mshow function since it creates another pop up window\n",
        "\n",
        "img = cv2.imread('/content/train/1.png')\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "Beq7PyI8ZCow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df.head()"
      ],
      "metadata": {
        "id": "KmZ-QkE0ZjhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_list = list(labels_df['id']) # creating an iteratvive array"
      ],
      "metadata": {
        "id": "k97a2EJRa5A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(id_list)"
      ],
      "metadata": {
        "id": "NprlAzEZbJQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Processing\n",
        "# Converting 50,000 Images to 50,000 numpy arrays and storing them in a list\n",
        "# All the images must be of the same size, if not we have to use reshape function to reshapeevery image to a common dimension value\n",
        "# Here all the images are already in same size 32*32\n",
        "train_data_folder = '/content/train/'\n",
        "data = []\n",
        "\n",
        "for id in id_list:\n",
        "  image = Image.open(train_data_folder + str(id) + '.png') # opening images using PIL Library\n",
        "  image = np.array(image) # converting images to numpy arrays\n",
        "  data.append(image) # Storing image numpy arrays in a list\n",
        "\n"
      ],
      "metadata": {
        "id": "6aXOUv1LbkiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "id": "8deQaQRkejqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "GUherkhEgnJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data[0])"
      ],
      "metadata": {
        "id": "da8-PnPegpmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0].shape"
      ],
      "metadata": {
        "id": "qh8Iw_AGgyIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[0]) # Example"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1hBeHvIdg3WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the labels list and images list to numpy arrays\n",
        "X = np.array(data)\n",
        "Y = np.array(labels)"
      ],
      "metadata": {
        "id": "TiJnSDJKhZgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(X)"
      ],
      "metadata": {
        "id": "ZGi49QTZkKy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "lqh2KK9JkM87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Splitting Training data into train and test data"
      ],
      "metadata": {
        "id": "jiYYw66ckiR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 2)"
      ],
      "metadata": {
        "id": "MvAJRjKxk-Ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)"
      ],
      "metadata": {
        "id": "goHd1TQrlnSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "pTHMAiM3lpIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Scaling the Images data between 0 to 1"
      ],
      "metadata": {
        "id": "G3C6wav9nxRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled = X_train/255\n",
        "X_test_scaled = X_test/255"
      ],
      "metadata": {
        "id": "OUc9IRXdl00r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_scaled)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VxMLlss6oHgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Building the Neural Network"
      ],
      "metadata": {
        "id": "0ADsKOi7ojNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "XWWclZ3ooNy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_classes = 10\n",
        "# Setting up the layers of Neural Network\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape = (32,32,3)),\n",
        "    keras.layers.Dense(64, activation = 'relu'), # hidden layer\n",
        "    keras.layers.Dense(num_of_classes, activation = 'softmax') # for multiclass classification we use here softmax as a activation function\n",
        "])"
      ],
      "metadata": {
        "id": "Uvi-VAhl12D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the neural network\n",
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['acc'])"
      ],
      "metadata": {
        "id": "KAM97-nH1_jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the neural network\n",
        "model.fit(X_train_scaled, Y_train, validation_split= 0.1, epochs = 20)"
      ],
      "metadata": {
        "id": "PQUaL9Zj2rI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Training the dataset using ResNet50 Model"
      ],
      "metadata": {
        "id": "nxcZ5Z7P5mFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all the libraries and the functions required to build ResNet50\n",
        "from tensorflow.keras import Sequential, layers, models\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras import optimizers\n"
      ],
      "metadata": {
        "id": "yEtIPmf34Fr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convolutional_base = ResNet50(weights = 'imagenet', include_top = False, input_shape = (256,256,3)) # include_top = False suggests to not include the output layer of the network\n",
        "convolutional_base.summary()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xD2aukNl59WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.UpSampling2D((2,2))) #scale the image by 2x to get a image with dimension 64*64\n",
        "model.add(layers.UpSampling2D((2,2))) #images output with dimension 128*128\n",
        "model.add(layers.UpSampling2D((2,2))) #images output with dimension 256*256 which is required for ResNet50 model\n",
        "model.add(convolutional_base) #using ResNet50 model\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(128, activation = 'relu'))\n",
        "model.add(layers.Dropout(0.5)) # To reduce the risk of overfitting\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(64, activation = 'relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(num_of_classes, activation = 'softmax'))\n",
        "\n"
      ],
      "metadata": {
        "id": "kKWytu7RAiAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = optimizers.RMSprop(learning_rate=2e-5), loss = 'sparse_categorical_crossentropy', metrics = ['acc'])"
      ],
      "metadata": {
        "id": "fmzf9lSlAkFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs = 10)"
      ],
      "metadata": {
        "id": "-FO0rIhJE1QK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting our loss and accuracy change\n",
        "h = history\n",
        "# loss value\n",
        "plt.plot(h.history['loss'], label = 'train loss')\n",
        "plt.plot(h.history['val_loss'], label = 'validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Accuracy value\n",
        "plt.plot(h.history['acc'], label = 'train accuracy')\n",
        "plt.plot(h.history['val_acc'], label = 'validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "cUTHcMWPFcB2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}